\section{Design}
Not sufficient to set parallelism just at application start, need to scale up and down. Machine load may change over time. Application requirements may change within a single run

\subsection{Mechanism for communicating}
\begin{enumerate}
  \item Use kernel memory (must modify kernel)
  \begin{itemize}
    \item OS: schedulers already quite complex. Must serve many masters; hard to make changes without harming certain workloads. Don't want to change the kernel if we can improve performance in user space \cite{lozi2016linux}
  \end{itemize}
  \item User space
\end{enumerate}

\subsection{Thread library}
Similar to Intel Thread Building Blocks \cite{reinders2007intel}, but dynamically scale number of workers across applications, rather than just across workers
\begin{itemize}
  \item Types of blocks: iterative / non-iterative parallelized operations
  \item DAG
  \item Unstructured
\end{itemize}

Global queue vs. fixed partition + work stealing

Min/max number of threads set by application developer

I/O and CPU pools treated differently in most libs

\begin{figure}
\centering
  \includegraphics[width=8cm,height=4cm]{overhead.png}
  \caption{What is performance overhead of thread library over pthreads?}
\end{figure}
\subsection{Driver application}
Track CPU utilization by application (any other metrics?)
Change target parallelism (how to decide, when to decide, how much to change by, which to change)
Change CPU share or quota
\subsection{Client applications}
