\section{Introduction}

In recent years, economic and physical realities have pushed chip designers, application developers, and system administrators to rely increasingly on parallelism to satisfy performance demands~\cite{mack2011fifty}. 

Historically, the simplest way to increase application performance was to increase the clock speed of the running CPU. In general, increases in clock speed were driven by shrinking the die on the chip. However, the industry has reached the limits of this strategy: issues such as excess heat dissipation and quantum tunnelling have slowed the pace of miniaturization \cite{kish2002end}.

As a result, the semiconductor industry has been turning to multiprocessing designs to deliver steady performance gains. For over a decade now, multi-core processors have been widely available, utilizing the increasing number of transistors on a chip without a concomitant increase the CPU clock rates.  As an example, Intel introduced its first dual-core processor in 2005~\cite{intel2005pentiumee}.  9 years later, Intel introduced a multiprocessor with 60 cores capable of running 240 threads in parallel~\cite{intel2013xeonphi3120a}.

However, parallel programs struggle to keep pace with the number of cores available, leading to a second trend: an increase in multi-tenancy in order to fully utilize processing hardware.

\subsection{Cloud computing and multi-tenancy}
Coincident with the the rise of hardware parallelism has been a shift to cloud-based computing. The availability of high-capacity networks, commodity hardware, and virtualization technologies made it attractive for many users to outsource their computing infrastructure to a specialized provider.

To achieve the economies of scale necessary to make cloud computing feasible, service providers commonly share hardware resources among many unrelated applications, while providing the illusion that each application is the sole user of its machine.

This illusion is maintained with the help of hardware and software virtualization. Technologies such as virtual machines and containers attempt to hide the multi-tenant nature of the system from users by further abstracting away details of the underlying hardware.

\subsection{Needs of high-performance parallelism and cloud computing environment are in tension}
Any resource allocation scheme for the cloud requires a delicate balance between application and service provider needs. 

Individual applications would like maximum performance for cost. In highly parallel applications, this requires intimate knowledge of the underlying hardware and operating system resources, as well as the guarantee that other actors will not interfere with them. 

Cloud providers would like to maximize resource sharing to keep hardware costs low. In addition, they would like high global throughput in order to increase the number of new users they can take on.

These desires are fundamentally at odds. Were each individual application to have its way, they would receive a dedicated server, increasing costs beyond what is feasible for the for the provider. Were the cloud provider to have their way, application performance would suffer greatly.

This has resulted in an uneasy truce between users and providers. Applications that are sensitive to noisy neighbors over-provision in order to reserve excess capacity, while cloud providers under-provision instances to backstop performance.

\subsection{Isolation abstraction limit application performance}
Maintaining the illusion of that each application is the sole user of a machine has served operating systems well. However, in a highly parallel, multi-tenant systems, this illusion can inhibit application performance.

Applications designed for high-performance parallelism are typically as "greedy" as possible, attempting to take full advantage of known hardware resources. When many such applications share the same hardware resources, contention for system resources increases, causing unnecessary overhead and causing both individual and total application throughput to suffer.

\subsection{The case for cooperative resource sharing}
For the most part, research on multi-tenancy in the cloud has borrowed heavily from earlier work on multiprogramming in operating systems~\cite{krebs2015performance}. Particular emphasis has been placed on suitable ways to preempt or throttle bad actors in the system to maintain the illusion of isolation~~\cite{multitenancy2012enforcing}. 

However, modern cloud environments do not have the same characteristics as general-purpose operating systems. Often, servers run many copies of the same application for different users, with the application code being under the full control of the server owner.

Moreover, highly parallel computing workloads often do not benefit from systematic ``hiding'' of underlying hardware characteristics. As discussed above, parallel programs seek make full use of existing cores, and often assume they have exclusive access to these resources.

In such an environment, there is opportunity for a cooperative resource sharing model to enable ``denser'' multi-tenancy without sacrificing application performance.

Cooperation over resources requires that the operating system communicate information about resource state to user-level applications, allowing cooperating applications to adjust their run-time behavior accordingly.

This paper presents \mechfull{}s as a mechanism to implement cooperative resource sharing for highly parallel applications. The \mech{} has the following components:
\begin{itemize}
    \item A \textbf{message bus} enabling structured communication between the operating system and user-level applications.
    \item A \textbf{scheduler} that allocates resources between different applications and passes messages to them through the communication channel.
    \item A \textbf{client library} that allowed applications responds to scheduler messages by adjusting runtime behavior.
\end{itemize}

\subsection{Contributions}
Based on these observations, we present the following contributions:
\begin{enumerate}
  \item Observing that current operating system abstractions do not handle contention gracefully when running multiple parallel applications on the same manycore processor and that a cooperative approach may be more suitable
  \item Making the case for a structured and dynamic communication mechanism between applications and the operating system to restrict parallel applications and adjust the operating system scheduler
  \item Demonstrating that a cooperative approach with the right mechanism can improve system throughput by up to 60\%.
\end{enumerate}
